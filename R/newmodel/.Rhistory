?flexEL::qr_evalG()
# quantile example
n <- 20
p <- 2
X <- replicate(p-1, rnorm(n))
X <- cbind(1, X)
beta0 <- c(1, 2)
y <- c(X %*% beta0) + rnorm(n)
alpha <- 0.5
beta <- c(1, 2)
qr_evalG(y, X, alpha, beta, s = 1)
?flexEL::qrls_evalG
## simulate some data ##
n <- 20
p <- 2
q <- 2
X <- replicate(p-1, rnorm(n))
X <- cbind(1, X) # X may have an intercept term, if so, it should be explicit
Z <- replicate(q, rnorm(n)) # Z shall not have an intercept term
beta0 <- c(1, 2)
gamma0 <- c(0.5, 0.25)
sig20 <- 0.5
y <- c(X %*% beta0 + sqrt(sig20)*exp(Z %*% gamma0)*rnorm(n)) # with N(0,1) error term
## calculate G matrix given data and certain parameter values ##
# a single quantile level (with continuity correction)
alpha <- 0.5
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- 0
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
mu <- 47.91
sd <-  18.84
alpha <- .8
N <- 35000
samples <- rnorm(N, mean = mu, sd = sd)
l <- qnorm(.2, mean =  mu, sd = sd)
thresh <- 0.5
dataset <- list()
# Group 1: Y < l,216, which is dataset[[1]]
R20_data <- samples[which(samples < l)]
dataset[[1]] <- R20_data
# Group 2: Y>l, Y* < l
R20R100_data <- samples[which(samples > l)]
R20R100_observed <- c()
damage_table <- c()
for (ii in 1: length(R20R100_data)){
if(l > thresh*R20R100_data[ii]){
R20R100_observed[ii] <- 1/alpha * R20R100_data[ii] + l/thresh - 1/alpha*l/thresh
# 1 means 'damaged'
damage_table[ii] <- 1
}
else{
# 0 means 'nondamaged'
R20R100_observed[ii] <- R20R100_data[ii]
damage_table[ii] <- 0
}
}
g2g3 <- cbind(R20R100_observed,damage_table,R20R100_data)
# group3 data
g3 <- g2g3[g2g3[,1] > l,]
# Group 2: Y>l, Y* < l, dataset[[2]] is the number of pieces in group 2
g2 <-  g2g3[g2g3[,1] < l,]
# dataset[[2]] <- dim(g2)[1]
dataset[[2]] <- g2[,1]
# dataset[[2]] <- N - length(dataset[[1]]) - dim(damage_data)[1]
# dataset[[2]]/N
# check the probalibility of that interval
pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
dmglikgroup2 <- function(alpha){
# pxga <- pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
# lik <-  dbinom(dataset[[2]], size = N, prob = pxga, log = TRUE)
# return(-1*lik)
lik <- 0
for (jj in 1:length(dataset[[2]])){
lik <- lik + log(alpha) + dnorm(alpha*dataset[[2]][jj]+l/thresh-alpha*l/thresh, mean =  mu,sd = sd, log = TRUE) -
log(1 - pnorm(l, mean = mu, sd = sd))
}
return(-1*lik)
}
optimize(dmglikgroup2,c(0,1))
dataset[[2]]
dataset[[2]]
alpha*dataset[[2]]+l/thresh-alpha*l/thresh
max(alpha*dataset[[2]]+l/thresh-alpha*l/thresh)
l/thresh
l
min(alpha*dataset[[2]]+l/thresh-alpha*l/thresh)
alpha*l + l/thresh - alpha*l/thresh
max(alpha*dataset[[2]]+l/thresh-alpha*l/thresh)
dmglikgroup2 <- function(alpha){
# pxga <- pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
# lik <-  dbinom(dataset[[2]], size = N, prob = pxga, log = TRUE)
# return(-1*lik)
lik <- 0
for (jj in 1:length(dataset[[2]])){
lik <- lik + log(alpha) + dnorm(alpha*dataset[[2]][jj]+l/thresh-alpha*l/thresh, mean =  mu,sd = sd, log = TRUE) -
log(1 - pnorm(l, mean = mu, sd = sd))
}
return(-1*lik)
}
optimize(dmglikgroup2,c(0,1))
sd
sigma
dmglikgroup2 <- function(alpha){
# pxga <- pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
# lik <-  dbinom(dataset[[2]], size = N, prob = pxga, log = TRUE)
# return(-1*lik)
lik <- 0
for (jj in 1:length(dataset[[2]])){
lik <- lik + log(alpha) + dnorm(alpha*dataset[[2]][jj]+l/thresh-alpha*l/thresh, mean =  mu,sd = sd, log = TRUE) -
log(pnorm(alpha*l + l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd))
}
return(-1*lik)
}
optimize(dmglikgroup2,c(0,1))
alpha*l + l/thresh - alpha*l/thres
alpha*l + l/thresh - alpha*l/thresh
l
dmglikgroup2 <- function(alpha){
# pxga <- pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
# lik <-  dbinom(dataset[[2]], size = N, prob = pxga, log = TRUE)
# return(-1*lik)
lik <- 0
for (jj in 1:length(dataset[[2]])){
lik <- lik + log(alpha) + dnorm(alpha*dataset[[2]][jj]+l/thresh-alpha*l/thresh, mean =  mu,sd = sd, log = TRUE) -
log(1 - pnorm(l, mean = mu, sd = sd))
}
return(-1*lik)
}
optimize(dmglikgroup2,c(0,1))
dataset[[2]]
sigma <- 18.84
# dataset[[2]] <- N - length(dataset[[1]]) - dim(damage_data)[1]
# dataset[[2]]/N
# check the probalibility of that interval
pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
dataset[[2]]/N
# dataset[[2]] <- N - length(dataset[[1]]) - dim(damage_data)[1]
# length(dataset[[2]])/N
# check the probalibility of that interval
pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
# dataset[[2]] <- N - length(dataset[[1]]) - dim(damage_data)[1]
# length(dataset[[2]])/N
# check the probalibility of that interval
pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
length(dataset[[2]])/N
vignette("help", package = "flexEL").
vignette("help", package = "flexEL")
## simulate some data ##
n <- 20
p <- 2
q <- 2
X <- replicate(p-1, rnorm(n))
X <- cbind(1, X) # X may have an intercept term, if so, it should be explicit
Z <- replicate(q, rnorm(n)) # Z shall not have an intercept term
beta0 <- c(1, 2)
gamma0 <- c(0.5, 0.25)
sig20 <- 0.5
y <- c(X %*% beta0 + sqrt(sig20)*exp(Z %*% gamma0)*rnorm(n)) # with N(0,1) error term
## calculate G matrix given data and certain parameter values ##
# a single quantile level (with continuity correction)
alpha <- 0.5
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- 0
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
# multiple quantile levels (with continuity correction)
alpha <- c(0.25, 0.75)
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- c(-0.5, 0.5)
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
## simulate some data ##
n <- 20
p <- 2
q <- 2
X <- replicate(p-1, rnorm(n))
X <- cbind(1, X) # X may have an intercept term, if so, it should be explicit
Z <- replicate(q, rnorm(n)) # Z shall not have an intercept term
beta0 <- c(1, 2)
gamma0 <- c(0.5, 0.25)
sig20 <- 0.5
y <- c(X %*% beta0 + sqrt(sig20)*exp(Z %*% gamma0)*rnorm(n)) # with N(0,1) error term
## calculate G matrix given data and certain parameter values ##
# a single quantile level (with continuity correction)
alpha <- 0.5
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- 0
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
# multiple quantile levels (with continuity correction)
alpha <- c(0.25, 0.75)
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- c(-0.5, 0.5)
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
alpha <- 0.5
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- 0
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
nu <- 0.2
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
nu <- 0.5
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
## calculate G matrix given data and certain parameter values ##
# a single quantile level (with continuity correction)
alpha <- 0.5
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- 0.5
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
nu <- 0
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
## simulate some data ##
n <- 20
p <- 2
q <- 2
X <- replicate(p-1, rnorm(n))
X <- cbind(1, X) # X may have an intercept term, if so, it should be explicit
Z <- replicate(q, rnorm(n)) # Z shall not have an intercept term
beta0 <- c(1, 2)
gamma0 <- c(0.5, 0.25)
sig20 <- 0.5
y <- c(X %*% beta0 + sqrt(sig20)*exp(Z %*% gamma0)*rnorm(n)) # with N(0,1) error term
## calculate G matrix given data and certain parameter values ##
# a single quantile level (with continuity correction)
alpha <- 0.5
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- 0
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
# multiple quantile levels (with continuity correction)
alpha <- c(0.25, 0.75)
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- c(-0.5, 0.5)
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
## calculate G matrix given data and certain parameter values ##
# a single quantile level (with continuity correction)
alpha <- 0.5
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- 0
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
nu <- 0.2
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
nu <- 0
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
nu <- 0.2
qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
?flexEL::CensEL
?flexEL::GenEL
G <- qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
# CensEL$new(n_obs, n_eqs)
flexEL::logEL(G, supp_adj = FALSE, grad = TRUE)
?flexEL::qrls_evalG
qrls_neglogel <- function(theta){
beta <- theta[1:2]
gamma <- theta[3:4]
sig2 <- theta[5]
nu <- theta[6]
alpha <- .5
G <- qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
G
}
theta <- c(1,2,.5,.25,.5,.2)
qrls_neglogel <- function(theta){
beta <- theta[1:2]
gamma <- theta[3:4]
sig2 <- theta[5]
nu <- theta[6]
alpha <- .5
G <- qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
flexEL::logEL(G, supp_adj = FALSE, grad = TRUE)
}
qrls_neglogel(theta)
nlmout <- nlm(f =qrls_neglogel, p = theta)
qrls_neglogel
nlmout <- nlm(f = qrls_neglogel, p = theta)
flexEL::logEL(G, supp_adj = FALSE)
qrls_neglogel <- function(theta){
beta <- theta[1:2]
gamma <- theta[3:4]
sig2 <- theta[5]
nu <- theta[6]
alpha <- .5
G <- qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
flexEL::logEL(G, supp_adj = FALSE)
}
theta <- c(1,2,.5,.25,.5,.2)
qrls_neglogel(theta)
nlmout <- nlm(f = qrls_neglogel, p = theta)
nlmout$estimate
theta
qrls_neglogel <- function(theta){
beta <- theta[1:2]
gamma <- theta[3:4]
sig2 <- theta[5]
nu <- theta[6]
alpha <- .5
G <- qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
-flexEL::logEL(G, supp_adj = FALSE)
}
optim(theta,qrls_neglogel())
optim(theta,qrls_neglogel
)
?optim
optim(theta,qrls_neglogel, method = "BFGS")
theta <- c(2,1,.5,.25,.5,.2)
qrls_neglogel(theta)
nlmout <- nlm(f = qrls_neglogel, p = theta)
optim(theta,qrls_neglogel, method = "BFGS")
qrls_neglogel(theta)
theta <- c(2,1,.5,.25,.5,.2)
theta <- c(1,1,.5,.25,.5,.2)
qrls_neglogel(theta)
theta <- c(1,3,.5,.25,.5,.2)
qrls_neglogel(theta)
theta <- c(1,2,.5,.25,.5,.2)
qrls_neglogel(theta)
X
theta <- c(1.2,2,.5,.25,.5,.2)
qrls_neglogel(theta)
theta <- c(1,2,.6,.25,.5,.2)
qrls_neglogel(theta)
theta <- c(1,2,.9,.25,.5,.2)
qrls_neglogel(theta)
theta <- c(1,2.1,.9,.25,.5,.2)
qrls_neglogel(theta)
optim(theta,qrls_neglogel, method = "BFGS")
theta <- c(1,2.5,.9,.25,.5,.2)
qrls_neglogel(theta)
theta <- c(1,2.2,.9,.25,.5,.2)
qrls_neglogel(theta)
theta <- c(1,2.1,.9,.25,.5,.2)
qrls_neglogel(theta)
theta <- c(1,2.1,.9,.25,.9,.2)
qrls_neglogel(theta)
theta <- c(1,2.1,.9,.25,.4,.2)
qrls_neglogel(theta)
theta <- c(1,2.1,.9,.25,.4,.5)
qrls_neglogel(theta)
optim(theta,qrls_neglogel, method = "BFGS")
\begin{equation}
\rho_{S,\tau}(u;s) = u\cdot(\tau - S(u;s)),
\end{equation}
Usage of quantile regression in \pkg{flexEL} is very similar to mean regression in the last section. Moreover, one can simultaneously estimte parameters at multiple quantile levels both with the location and location-scale models. With the location model, both the intercept and the slope parameters can be different at different quantile levels. Essentially, the `G` matrix is obtained by stacking together multiple `G` matrices each at one quantile level. This is one advantage of quantile regression when heteroscedasticity presents. With the location-scale model, only the quantile parameter $\nu_{\tau}$ is different at different quantile levels, since heteroscedasticity can be handled by the scale function.
## simulate some data ##
n <- 20
p <- 2
q <- 2
X <- replicate(p-1, rnorm(n))
X <- cbind(1, X) # X may have an intercept term, if so, it should be explicit
Z <- replicate(q, rnorm(n)) # Z shall not have an intercept term
beta0 <- c(1, 2)
gamma0 <- c(0.5, 0.25)
sig20 <- 0.5
y <- c(X %*% beta0 + sqrt(sig20)*exp(Z %*% gamma0)*rnorm(n)) # with N(0,1) error term
## calculate G matrix given data and certain parameter values ##
# a single quantile level (with continuity correction)
alpha <- 0.5
beta <- c(1, 2)
gamma <- c(0.5, 0.25)
sig2 <- 0.5
nu <- 0.2
G <- qrls_evalG(y, X, Z, alpha, beta, gamma, sig2, nu, s = 1)
G
y - X%*%beta
yXb <- as.numeric(y - X %*% beta)
eZg <- exp(as.numeric(Z %*% gamma))
(yXb/eZg^2) * X                # beta
G[,1:2]
identical(G[,1:2],(yXb/eZg^2) * X  )              # beta
(yXb/eZg^2) * X
G[,1:2]
(yXb/eZg^2) * X
G[,1:2]
identical(G[,1:2],(yXb/eZg^2) * X  )              # beta
class((yXb/eZg^2) * X  )
identical(G[,1:2],as.matrix((yXb/eZg^2) * X  )  )            # beta
class(G[,1:2])
G[,1:2]
as.matrix((yXb/eZg^2) * X           # beta
G[,1:2]
as.matrix((yXb/eZg^2) * X
(yXb/eZg^2) * X
(yXb/eZg^2) * X
G[,1:2]
# gamma
G[,3:4]
(1 - (yXb/(sigma*eZg))^2) * Z
# gamma
G[,3:4]
(1 - (yXb/(sigma*eZg))^2) * Z
(1 - (yXb^2/(sigma^2*eZg))) * Z
# gamma
G[,3:4]
(1 - (yXb^2/(sigma^2*eZg))) * Z
# gamma
G[,3:4]
(1 - (yXb/(sigma*eZg))^2) * Z
# gamma
G[,3:4]
(1 - (yXb/(sigma*eZg))^2) * Z
(1 - (yXb/(sigma*eZg))^2) * Z
G
(yXb/eZg^2) * X
# gamma
G[,3:4]
(1 - (yXb/(sigma*eZg))^2) * Z
(1 - (yXb/(sig2*eZg))^2) * Z
# gamma
G[,3:4]
(1 - (yXb/(sig2*eZg))^2) * Z
(1 - (yXb/(sqrt(sig2)*eZg))^2) * Z
# gamma
G[,3:4]
(1 - (yXb/(sqrt(sig2)*eZg))^2) * Z
sigma <- sqrt(sig2)
(1 - (yXb/(sigma*eZg))^2) * Z
# gamma
G[,3:4]
# sigma
G[,5]
(yXb/(sigma*eZg))^2 - 1
# nu
G[m6]
# nu
G[,6]
check_smooth_dx(yXb/(sigma*eZg) - nu, tau, s)
check_smooth_dx <- function(x, tau, s) {
(tau - 1/(1+exp(s*x))) + x*(s*exp(s*x)/((1+exp(s*x))^2))
}
check_smooth_dx(yXb/(sigma*eZg) - nu, tau, s)
check_smooth_dx(yXb/(sigma*eZg) - nu, tau = .5, s)
check_smooth_dx(yXb/(sigma*eZg) - nu, tau = .5, s = 1)
check_smooth_dx(yXb/(sigma*eZg) - nu, tau, s)
# nu
G[,6]
check_smooth_dx(yXb/(sigma*eZg) - nu, tau = .5, s = 1)
# nu
check_smooth_dx <- function(x, tau, s) (tau - 1/(1+exp(s*x))) + x*(s*exp(s*x)/((1+exp(s*x))^2))
G[,6]
check_smooth_dx(yXb/(sigma*eZg) - nu, tau = .5, s = 1)
mu <- 47.91
sd <-  18.84
sigma <- 18.84
alpha <- .8
N <- 35000
samples <- rnorm(N, mean = mu, sd = sd)
l <- qnorm(.2, mean =  mu, sd = sd)
thresh <- 0.5
dataset <- list()
# Group 1: Y < l,216, which is dataset[[1]]
R20_data <- samples[which(samples < l)]
dataset[[1]] <- R20_data
# Group 2: Y>l, Y* < l
R20R100_data <- samples[which(samples > l)]
R20R100_observed <- c()
damage_table <- c()
for (ii in 1: length(R20R100_data)){
if(l > thresh*R20R100_data[ii]){
R20R100_observed[ii] <- 1/alpha * R20R100_data[ii] + l/thresh - 1/alpha*l/thresh
# 1 means 'damaged'
damage_table[ii] <- 1
}
else{
# 0 means 'nondamaged'
R20R100_observed[ii] <- R20R100_data[ii]
damage_table[ii] <- 0
}
}
g2g3 <- cbind(R20R100_observed,damage_table,R20R100_data)
# group3 data
g3 <- g2g3[g2g3[,1] > l,]
# Group 2: Y>l, Y* < l, dataset[[2]] is the number of pieces in group 2
g2 <-  g2g3[g2g3[,1] < l,]
# dataset[[2]] <- dim(g2)[1]
dataset[[2]] <- g2[,1]
max(alpha*dataset[[2]]+l/thresh-alpha*l/thresh)
alpha*l + l/thresh - alpha*l/thresh
# dataset[[2]] <- N - length(dataset[[1]]) - dim(damage_data)[1]
# length(dataset[[2]])/N
# check the probalibility of that interval
pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
dmglikgroup2 <- function(alpha){
# pxga <- pnorm(alpha*l+l/thresh - alpha*l/thresh, mean = mu, sd = sd) - pnorm(l, mean = mu, sd = sd)
# lik <-  dbinom(dataset[[2]], size = N, prob = pxga, log = TRUE)
# return(-1*lik)
lik <- 0
for (jj in 1:length(dataset[[2]])){
lik <- lik + log(alpha) + dnorm(alpha*dataset[[2]][jj]+l/thresh-alpha*l/thresh, mean =  mu,sd = sd, log = TRUE) -
log(1 - pnorm(l, mean = mu, sd = sd))
}
return(-1*lik)
}
max(alpha*dataset[[2]]+l/thresh-alpha*l/thresh)
alpha*l + l/thresh - alpha*l/thresh
optimize(dmglikgroup2,c(0,1))
