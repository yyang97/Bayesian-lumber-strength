{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99771c14",
   "metadata": {},
   "source": [
    "# Damage model \n",
    "The original model is \n",
    "\n",
    "\\begin{equation}\\label{eq: original model}\n",
    "y^*  = y \\cdot I\\{c \\cdot y > l\\} + \\alpha \\cdot y \\cdot I\\{c \\cdot y < l\\}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "# Smooth function\n",
    "\n",
    "Note that we have the indicator function in the model we might consider the smooth function:\n",
    "\\begin{equation}\\label{eq: trans function}\n",
    "S(x;s) = \\frac{1}{1 + \\exp(-s \\cdot x)}\n",
    "\\end{equation},\n",
    "where $s$ is the smoothing hyper-parameter to control the smoothness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb933ea",
   "metadata": {},
   "source": [
    "Then the model becomes \n",
    "$$\n",
    "y^*  = y \\cdot \\frac{1}{1 + \\exp(-s\\cdot(cy-l))} + \\alpha \\cdot y \\cdot \\frac{1}{1 + \\exp(-s\\cdot(l-cy))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca7c62",
   "metadata": {},
   "source": [
    "We have $y \\geq y^*$.\n",
    "\n",
    "The lumber have three groups:\n",
    "\n",
    "- Group 1: $y <l$, $y^* < l$, i.e., $y^* <y < l$. The lumber pieces are broken blow the proof loading.\n",
    "- Group 2: $y >l$, $y^* < l$, i.e. $y^*<l<y$. The lumber pieces are broken during the proof loading process. This groups we only knows how many pieces. \n",
    "\n",
    "update: this group should be $0<y^*<l<y$. So $F_y(h^{-1}(l)) - F_y(h^{-1}(\\max(0,h^{-1}(l)))$\n",
    "- Group 3: $y >l$, $y^* > l$, i.e. $l<y^*<y$. The lumber pieces survived in the proof-loading. And then we destruct them to test their strength.\n",
    "\n",
    "\n",
    "# The PDF calculation \n",
    "\n",
    "Given $Y \\sim N(\\mu, \\sigma^2)$, $Y^* = h(Y)$. Then the pdf of $Y^*$,\n",
    "$$\n",
    "f_{Y^*}(y^*) = f_{Y}(h^{-1}(y^*))|\\frac{d}{dy^*}h^{-1}(y^*)|,\n",
    "$$\n",
    "where $f_Y()$ is the pdf of $Y$, i.e., normal. \n",
    "\n",
    "Following this, We need the numerical function of $h^{-1}(y^*)$, and its numerical gradient $\\frac{d}{dy^*}h^{-1}(y^*)$. (The analytical form doesn't seem available.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbcc1a1-7850-4a9b-aca9-1517f6ea7ff4",
   "metadata": {},
   "source": [
    "# The range of alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e450c6-958d-4f16-83e1-2d4122d0a054",
   "metadata": {},
   "source": [
    "For the model \n",
    "\n",
    "\\begin{equation}\n",
    "y^*  = y \\cdot I\\{c \\cdot y > l\\} + \\alpha \\cdot y \\cdot I\\{c \\cdot y < l\\}.\n",
    "\\end{equation}\n",
    "\n",
    "What happened if $\\alpha < c$?\n",
    "\n",
    "then $\\alpha*y < c*y <l $. It means that all damaged pieces are censored. So we don't have damaged pieces. The remaining pieces in group 3 are all undamaged. Then we can only have the range of $\\alpha$ but no specific estimate.\n",
    "\n",
    "In bivarite dataset, we don't have this problem because we have $c*x$ and $\\alpha*y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ee4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jaxopt\n",
    "import jax.numpy as jnp\n",
    "import pyreadr\n",
    "import projplot as pjp\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daed985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "\n",
    "def indicator(x):\n",
    "    return(jnp.select([x>0,x<=0],[1,0]))\n",
    "\n",
    "def logit(x):\n",
    "    return(jnp.log(x/(1-x)))\n",
    "\n",
    "\n",
    "def expit(x):\n",
    "    return 1/(1+jnp.exp(-x))\n",
    "\n",
    "def exp_smooth(x):\n",
    "    return(jnp.select(\n",
    "    [x >0, x<=0],[jnp.exp(-1/(x+ 0.001)),0]))\n",
    "\n",
    "def g_smooth(x):\n",
    "    return(exp_smooth(x)/(exp_smooth(x) + exp_smooth(1-x)))\n",
    "\n",
    "def sigmoid(x, s):\n",
    "    # x = jnp.array(x)\n",
    "    # a = jnp.array(a)\n",
    "    return 0.5 * (jnp.tanh(x * s / 2) + 1)\n",
    "\n",
    "def dmgmodel_ind(y,alpha,l,c):\n",
    "    return(y*indicator(c*y-l) + alpha*y*indicator(l-c*y))\n",
    "\n",
    "\n",
    "def dmgmodel_py(y,alpha,l,c,s):\n",
    "    #return(y*jax.scipy.stats.norm.cdf(c*y-l) + alpha*y*jax.scipy.stats.norm.cdf(l-c*y))\n",
    "    return(y*sigmoid(c*y-l,s) + alpha*y*sigmoid(l-c*y,s))\n",
    "\n",
    "    #return(y*g_smooth(c*y-l) + alpha*y*g_smooth(l-c*y))\n",
    "\n",
    "def dmgmodel_root_py(y,alpha,l,c,s,ystar):\n",
    "    return(dmgmodel_py(y,alpha,l,c,s) - ystar)\n",
    "\n",
    "\n",
    "\n",
    "def dmginverse_py(ystar,alpha,l,c,s):\n",
    "    ystar = jnp.array(ystar)\n",
    "    bisec = jaxopt.Bisection(\n",
    "        optimality_fun=dmgmodel_root_py,\n",
    "        lower = 0,\n",
    "        upper = 10000,\n",
    "        check_bracket = False)\n",
    "    return(bisec.run(alpha = alpha,l = l, c= c ,s = s,ystar = ystar).params)\n",
    "\n",
    "def dmginvgrad_py(ystar,alpha,l,c,s):\n",
    "    grad_func = jax.grad(dmginverse_py,0)\n",
    "    return(jnp.abs(grad_func(ystar,alpha,l,c,s)))\n",
    "\n",
    "def dmglik_py(ystar,alpha,l,c,s,mu,sigma):\n",
    "    y =  dmginverse_py(ystar,alpha,l,c,s)\n",
    "    return(jax.scipy.stats.norm.logpdf(y,loc = mu,scale = sigma)+ \n",
    "           jnp.log(dmginvgrad_py(ystar,alpha,l,c,s))\n",
    "          )\n",
    "\n",
    "\n",
    "def dmglik_vmap(y_group,alpha,l,c,s,mu,sigma):\n",
    "    y_group = jnp.array(y_group)\n",
    "    lik = jax.vmap(lambda y_group: dmglik_py(ystar = y_group,\n",
    "                                             alpha = alpha,l = l, c= c,s =s,mu = mu, sigma=sigma))(y_group)\n",
    "    return(jnp.sum(lik))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69987433-5465-4fe4-b3a9-5f1d1bb5e342",
   "metadata": {},
   "source": [
    "change $s = 10$ to $s =1$ can make loglik of alpha and c more smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1bc223-501d-4e52-ab4d-59ce451889ca",
   "metadata": {},
   "source": [
    "# In the second case, $\\alpha <c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ec2610-b70c-4d97-ad06-890d5db13606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the orignal sample size \n",
    "#N = 30000\n",
    "N = 300\n",
    "mu = 48\n",
    "sigma = 19\n",
    "l =  32\n",
    "# alpha = 0.6\n",
    "# c = 0.65\n",
    "alpha = 0.65\n",
    "c = 0.68\n",
    "s = 10\n",
    "\n",
    "N_marginal = 139\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7190cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_draw = jnp.zeros(shape = (100, 4))\n",
    "@jax.jit\n",
    "def negdmglik_jax(theta,y_obs_g1,y_obs_g2,y_obs_g3,y_obs_g4):\n",
    "    mu = theta[0]\n",
    "    sigma = theta[1]\n",
    "    alpha = theta[2]\n",
    "    c = theta[3]\n",
    "    lik1 = jnp.sum(jax.scipy.stats.norm.logpdf(y_obs_g1,loc = mu, scale = sigma))\n",
    "    #lik1 = dmglik_vmap(y_group = y_obs_g1,alpha = alpha,l = l, c = c,s = s, mu = mu, sigma = sigma)\n",
    "#     lik2 = y_obs_g2*jnp.log(\n",
    "#         jax.scipy.stats.norm.cdf(dmginverse_py(l,alpha,l,c,s), loc=mu, scale=sigma) - \n",
    "#         jax.scipy.stats.norm.cdf(l, loc=mu, scale=sigma)\n",
    "#     )\n",
    "    lik2 = y_obs_g2*jnp.log(\n",
    "    jax.scipy.stats.norm.cdf(dmginverse_py(l,alpha,l,c,s), loc=mu, scale=sigma) - \n",
    "    jax.scipy.stats.norm.cdf(dmginverse_py(jnp.maximum(0.1,dmgmodel_py(l,alpha,l,c,s)),alpha,l,c,s), loc=mu, scale=sigma)\n",
    "    )\n",
    "    lik3 = dmglik_vmap(y_group = y_obs_g3,alpha = alpha,l = l, c = c,s = s, mu = mu, sigma = sigma)\n",
    "    lik4 = jnp.sum(jax.scipy.stats.norm.logpdf(y_obs_g4,loc = mu, scale = sigma))\n",
    "\n",
    "    return(-lik1 - lik2-lik3-lik4)\n",
    "#params_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa8f7b0-48fc-4e5a-a92d-d1059e5c240e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3911772289.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    for (ii in range(100)):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# data generation \n",
    "key = jax.random.PRNGKey(0)\n",
    "subkeys = jax.random.split(key, num=N)\n",
    "\n",
    "\n",
    "for ii in range(100):\n",
    "\n",
    "    y = sigma*jax.random.normal(subkeys[ii], shape=(N, )) + mu\n",
    "\n",
    "    #y = y[y>0]\n",
    "\n",
    "    # g1\n",
    "    y_obs_g1  = y[y<l]\n",
    "\n",
    "\n",
    "    # g23_star\n",
    "    g23 = y[y>l]\n",
    "    g23_star = jax.vmap(lambda y: dmgmodel_py(y,alpha,l,c,s))(g23)\n",
    "\n",
    "\n",
    "    # g3\n",
    "    y_obs_g3 = g23_star[g23_star > l]\n",
    "\n",
    "    # g2\n",
    "    y_obs_g2 = N - len(y_obs_g1) - len(y_obs_g3)\n",
    "\n",
    "    #y_obs_g2 = jnp.shape(y)[0] - len(y_obs_g1) - len(y_obs_g3)\n",
    "\n",
    "    # g4, is all marginal data\n",
    "    y_obs_g4 = sigma*jax.random.normal(subkeys[0], shape=(N_marginal, )) + mu\n",
    "    \n",
    "    theta0 = jnp.array([mu,sigma,alpha,c])\n",
    "\n",
    "    solver = jaxopt.ScipyMinimize(method = \"Nelder-Mead\",fun=negdmglik_jax)\n",
    "    res = solver.run(theta0,y_obs_g1,y_obs_g2,y_obs_g3,y_obs_g4)\n",
    "\n",
    "    # solver = jaxopt.BFGS(fun=negdmglik_jax)\n",
    "    # res = solver.run(theta0)\n",
    "\n",
    "    params_draw = params_draw.at[ii,:].set(res.params)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab3fb5-cd6a-4816-8674-2cc6b0b76aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # negdmglik_jax(theta0)\n",
    "# #dmglik_vmap(y_group = y_obs_g3,alpha = alpha,l = l, c = c,s = s, mu = mu, sigma = sigma)\n",
    "\n",
    "# #dmglik_py(y_obs_g3[0][0],alpha,l,c,s,mu,sigma)\n",
    "\n",
    "# #dmglik_vmap(y_obs_g3,alpha,l,c,s,mu,sigma)\n",
    "\n",
    "# s= 10\n",
    "# l = l \n",
    "# y_obs_g1 = y_obs_g1\n",
    "# y_obs_g2 = y_obs_g2\n",
    "# y_obs_g3 = y_obs_g3\n",
    "# y_obs_g4 = y_obs_g4\n",
    "# @jax.jit\n",
    "# def negdmglik_jax(theta,y_obs_g1,y_obs_g2,y_obs_g3,y_obs_g4):\n",
    "#     mu = theta[0]\n",
    "#     sigma = theta[1]\n",
    "#     alpha = theta[2]\n",
    "#     c = theta[3]\n",
    "#     lik1 = jnp.sum(jax.scipy.stats.norm.logpdf(y_obs_g1,loc = mu, scale = sigma))\n",
    "#     #lik1 = dmglik_vmap(y_group = y_obs_g1,alpha = alpha,l = l, c = c,s = s, mu = mu, sigma = sigma)\n",
    "# #     lik2 = y_obs_g2*jnp.log(\n",
    "# #         jax.scipy.stats.norm.cdf(dmginverse_py(l,alpha,l,c,s), loc=mu, scale=sigma) - \n",
    "# #         jax.scipy.stats.norm.cdf(l, loc=mu, scale=sigma)\n",
    "# #     )\n",
    "#     lik2 = y_obs_g2*jnp.log(\n",
    "#     jax.scipy.stats.norm.cdf(dmginverse_py(l,alpha,l,c,s), loc=mu, scale=sigma) - \n",
    "#     jax.scipy.stats.norm.cdf(dmginverse_py(jnp.maximum(0.1,dmgmodel_py(l,alpha,l,c,s)),alpha,l,c,s), loc=mu, scale=sigma)\n",
    "#     )\n",
    "#     lik3 = dmglik_vmap(y_group = y_obs_g3,alpha = alpha,l = l, c = c,s = s, mu = mu, sigma = sigma)\n",
    "#     lik4 = jnp.sum(jax.scipy.stats.norm.logpdf(y_obs_g4,loc = mu, scale = sigma))\n",
    "\n",
    "#     return(-lik1 - lik2-lik3-lik4)\n",
    "\n",
    "# theta0 = jnp.array([mu,sigma,alpha,c])\n",
    "\n",
    "\n",
    "\n",
    "# # negdmglik_jax(theta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c93a3-f0db-4f3b-8cdc-88389fc7187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta0 = jnp.array([mu,sigma,alpha,c])\n",
    "\n",
    "# solver = jaxopt.ScipyMinimize(method = \"Nelder-Mead\",fun=negdmglik_jax)\n",
    "# res = solver.run(theta0,y_obs_g1,y_obs_g2,y_obs_g3,y_obs_g4)\n",
    "\n",
    "# # solver = jaxopt.BFGS(fun=negdmglik_jax)\n",
    "# # res = solver.run(theta0)\n",
    "\n",
    "# res.params,res.state\n",
    "# theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365f648-50ef-4516-9bd1-6cf588c7a72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108db71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
